"""
è®­ç»ƒ-è¯„ä¼°ï¼ˆæ”¯æŒ PQ å’Œ V-Î¸ è·¯çº¿ï¼ŒV1.1 å¯¹é½ï¼Œæ”¯æŒå¤§æ‰¹æ¬¡ + ç¼–è¯‘åŠ é€Ÿï¼‰

è¦ç‚¹
- PQ è·¯çº¿ï¼šç«¯å£çº§ç›‘ç£ + å®¹é‡å®ˆæŠ¤ + æ¯çº¿ä¸€è‡´æ€§çº¦æŸ
- V-Î¸ è·¯çº¿ï¼šç”µå‹ Huber æŸå¤± + ç›¸è§’å·® MSE æŸå¤± + å¯é€‰å®¹é‡çº¦æŸ
- å¤§ batchï¼šcollate æŒ‚ bus_ptr/corr_ptrï¼›æŸå¤±æŒ‰"é€å›¾å‡å€¼â†’è·¨å›¾å‡å€¼"åšå…¬å¹³èšåˆã€‚
- åŠ é€Ÿï¼šAMP(bf16)ã€éé˜»å¡æ¬è¿ã€pin_memory / persistent_workers / prefetch_factorã€torch.compile(mode='reduce-overhead', dynamic=True)ã€‚
- æ ¡éªŒï¼šæ ¹æ®è·¯çº¿æ£€æŸ¥å¿…è¦å­—æ®µï¼ˆPQ: y_bus_pq, V-Î¸: y_bus_V, y_edge_sincosï¼‰
"""

import os
import sys
# å…è®¸ä½œä¸ºè„šæœ¬ç›´æ¥è¿è¡Œï¼šæŠŠä»“åº“æ ¹ç›®å½•åŠ å…¥ sys.pathï¼Œä½¿å¾— 'gnn.*' å¯å¯¼å…¥
if __package__ is None or __package__ == "":
    _repo_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    if _repo_root not in sys.path:
        sys.path.insert(0, _repo_root)

import os
import sys
import time
import logging
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from datetime import datetime
from tqdm import tqdm
from torch.utils.tensorboard import SummaryWriter
import torch.distributed as dist
from torch.utils.data.distributed import DistributedSampler
from contextlib import nullcontext
from torch_geometric.utils import scatter

from config import cfg
from model import BCGNN
from data import load_data, create_dataloader




# å·²ç§»é™¤éPQè·¯çº¿ç›¸å…³çš„æŸå¤±ä¸ä¸ç¡®å®šæ€§åŠ æƒï¼Œä»…ä¿ç•™ PQ è·¯çº¿ã€‚

"""
æ³¨ï¼šå·²åˆ é™¤çº¦170è¡Œç‰©ç†çº¦æŸç›¸å…³ä»£ç ï¼ŒåŒ…æ‹¬ï¼š
- ç”µå‹çº¦æŸè®¡ç®—
- è§’åº¦çº¦æŸè®¡ç®—  
- èµ°å»Šçº§å¯¼çº³èšåˆ
- æ½®æµæ–¹ç¨‹è®¡ç®—ï¼ˆP_ij, Q_ij, S_ijï¼‰
- å®¹é‡çº¦æŸæ£€æŸ¥
- ç‰©ç†æƒé‡è°ƒåº¦æœºåˆ¶
"""

# --- è®¾å¤‡ä¸æ—¥å¿—è®¾ç½® ---


def setup_ddp():
    """DDPåˆå§‹åŒ–ï¼Œè¿”å› (is_ddp, rank, local_rank, world_size, device)"""
    if "RANK" in os.environ and "WORLD_SIZE" in os.environ:
        rank = int(os.environ["RANK"])
        local_rank = int(os.environ.get("LOCAL_RANK", 0))
        world_size = int(os.environ["WORLD_SIZE"])
        dist.init_process_group(backend="nccl")
        torch.cuda.set_device(local_rank)
        device = f"cuda:{local_rank}"
        return True, rank, local_rank, world_size, device
    else:
        # å•å¡æˆ–CPUæ¨¡å¼
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        return False, 0, 0, 1, device

def setup_device():
    """è®¾ç½®GPUè®¾å¤‡"""
    if not torch.cuda.is_available():
        cfg.device = 'cpu'
        cfg.use_multi_gpu = False
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUè®­ç»ƒ")
        return cfg.device, None
    
    # GPUä¿¡æ¯
    print(f"ğŸš€ æ£€æµ‹åˆ° {torch.cuda.device_count()} å—GPU")
    for i in range(torch.cuda.device_count()):
        props = torch.cuda.get_device_properties(i)
        mem_gb = props.total_memory / 1024**3
        print(f"   GPU {i}: {props.name} ({mem_gb:.1f}GB)")
    
    # è®¾ç½®ä¸»GPU
    primary_gpu = cfg.gpu_ids[0] if cfg.gpu_ids else 0
    torch.cuda.set_device(primary_gpu)
    print(f"ğŸ“ ä¸»GPU: GPU {primary_gpu}")
    
    # æ¸…ç©ºGPUç¼“å­˜
    torch.cuda.empty_cache()
    
    device = f'cuda:{primary_gpu}'
    return device, cfg.gpu_ids if cfg.use_multi_gpu else None


def setup_logging():
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    # åˆ›å»ºlogger
    logger = logging.getLogger('BCGNN')
    logger.setLevel(logging.INFO)
    
    # æ–‡ä»¶handler
    fh = logging.FileHandler(os.path.join(cfg.log_dir, 'train.log'))
    fh.setLevel(logging.INFO)
    
    # æ§åˆ¶å°handler
    ch = logging.StreamHandler(sys.stdout)
    ch.setLevel(logging.INFO)
    
    # æ ¼å¼
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    fh.setFormatter(formatter)
    ch.setFormatter(formatter)
    
    logger.addHandler(fh)
    logger.addHandler(ch)
    
    return logger


def set_seed(seed):
    """è®¾ç½®éšæœºç§å­"""
    import random
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)


def compute_loss_vtheta(pred, batch, config, rank=0):
    """
    V-Î¸ è·¯çº¿æŸå¤±å‡½æ•°ï¼ˆç²¾ç®€ç‰ˆï¼šV + Î¸ + reconï¼‰

    Args:
        pred: æ¨¡å‹é¢„æµ‹å­—å…¸ {'V_pred': [B], 'sincos_pred': [E_tie,2], 'edge_pq': [E_tie,4]}
        batch: PyG Batchï¼ŒåŒ…å«æ ‡ç­¾ y_bus_V, y_edge_sincos, y_edge_pq
        config: é…ç½®å¯¹è±¡
        rank: DDP rank

    Returns:
        loss: æ€»æŸå¤±
        loss_dict: æŸå¤±å­—å…¸ï¼ˆç”¨äºè®°å½•ï¼‰
    """
    device = batch.x.device

    # ========== 1. ç”µå‹æŸå¤±ï¼šHuber(V_pred, y_bus_V) ==========
    V_pred = pred['V_pred']  # [B]
    y_V = batch.y_bus_V
    if y_V.device != device:
        y_V = y_V.to(device, non_blocking=True)  # [B]
    loss_V = F.huber_loss(V_pred, y_V, delta=0.01)

    # ========== 2. ç›¸è§’å·®æŸå¤±ï¼šMSE(sincos_pred, y_edge_sincos) ==========
    sincos_pred = pred['sincos_pred']  # [E_tie, 2]
    y_sincos = batch.y_edge_sincos
    if y_sincos.device != device:
        y_sincos = y_sincos.to(device, non_blocking=True)  # [E_tie, 2]
    loss_theta = F.mse_loss(sincos_pred, y_sincos)

    # ========== 3. åŠŸç‡é‡æ„ä¸€è‡´æ€§æŸå¤±ï¼šL1(edge_pq, y_edge_pq) ==========
    edge_pq_pred = pred['edge_pq']  # [E_tie, 4]
    y_edge_pq = batch.y_edge_pq
    if y_edge_pq.device != device:
        y_edge_pq = y_edge_pq.to(device, non_blocking=True)  # [E_tie, 4]
    loss_recon = F.l1_loss(edge_pq_pred, y_edge_pq)

    # ========== æ€»æŸå¤± ==========
    lambda_theta = getattr(config, 'lambda_theta', 1.0)
    lambda_recon = getattr(config, 'lambda_recon', 0.1)

    total_loss = loss_V + lambda_theta * loss_theta + lambda_recon * loss_recon

    loss_dict = {
        'loss_v': float(loss_V.detach().item()),  # ç»Ÿä¸€ä½¿ç”¨å°å†™é”®å
        'loss_theta': float(loss_theta.detach().item()),
        'loss_recon': float(loss_recon.detach().item()),
        'total': float(total_loss.detach().item())
    }

    # 4. å¯é€‰ï¼šå®¹é‡çº¦æŸï¼ˆæŒ‰çº¿ç‰ˆæœ¬ï¼‰
    if getattr(config, 'use_capacity_constraint', False) and 'edge_pq' in pred:
        # ä½¿ç”¨æŒ‰çº¿é¢„æµ‹çš„åŠŸç‡
        Pf = edge_pq_pred[:, 0]  # [E_tie]
        Qf = edge_pq_pred[:, 2]  # [E_tie]
        S_pred = torch.sqrt(Pf**2 + Qf**2 + 1e-12)

        # è·å–æ¯æ¡çº¿çš„å®¹é‡ä¸Šé™
        if hasattr(batch, 'tie_edge_indices') and batch.tie_edge_indices is not None:
            tie_edge_indices = batch.tie_edge_indices
            if tie_edge_indices.device != device:
                tie_edge_indices = tie_edge_indices.to(device, non_blocking=True)
            S_max = batch.edge_attr[tie_edge_indices, 2]  # edge_attr[:, 2] = S_max
        else:
            # å›é€€ï¼šä½¿ç”¨é»˜è®¤å€¼
            S_max = torch.ones_like(S_pred) * 1.0

        # å®¹é‡å®ˆæŠ¤æŸå¤±ï¼šReLU(S_pred - alpha * S_max)
        alpha = getattr(config, 'capacity_alpha', 0.95)
        loss_cap = torch.relu(S_pred - alpha * S_max).mean()

        # åŠ åˆ°æ€»æŸå¤±
        lambda_cap = getattr(config, 'lambda_capacity', 0.1)
        total_loss = total_loss + lambda_cap * loss_cap

        loss_dict['loss_capacity'] = float(loss_cap.detach().item())
        loss_dict['total'] = float(total_loss.detach().item())

    # 5. è®¡ç®— MAE æŒ‡æ ‡ï¼ˆç”¨äºç›‘æ§ï¼‰
    with torch.no_grad():
        # ç”µå‹MAE
        mae_V = torch.abs(V_pred - y_V).mean()
        loss_dict['mae_V'] = float(mae_V.item())

        # è§’åº¦è¯¯å·®ï¼ˆå•ä½åœ†ä¸Šçš„è§’è·ç¦»ï¼‰
        cos_err = (sincos_pred * y_sincos).sum(dim=1).clamp(-1, 1)
        theta_err = torch.acos(cos_err)  # radians
        mae_theta_deg = torch.rad2deg(theta_err.mean())
        loss_dict['mae_theta_deg'] = float(mae_theta_deg.item())

        # åŠŸç‡é‡æ„MAE
        mae_P = torch.abs(edge_pq_pred[:, :2] - y_edge_pq[:, :2]).mean()
        mae_Q = torch.abs(edge_pq_pred[:, 2:] - y_edge_pq[:, 2:]).mean()
        loss_dict['mae_P'] = float(mae_P.item())
        loss_dict['mae_Q'] = float(mae_Q.item())

    return total_loss, loss_dict


def train_epoch_simple(model, train_loader, optimizer, supervised_loss_fn, epoch, writer, logger, rank=0):
    """è®­ç»ƒä¸€ä¸ªepochï¼ˆæ”¯æŒAMPã€æ¢¯åº¦ç´¯ç§¯å’ŒDDPï¼‰"""
    model.train()
    
    # AMPå’Œæ¢¯åº¦ç´¯ç§¯è®¾ç½®
    use_amp = getattr(cfg, 'use_amp', False)
    amp_dtype = torch.bfloat16 if getattr(cfg, 'amp_dtype', 'fp16') == 'bf16' else torch.float16
    scaler = torch.amp.GradScaler('cuda', enabled=use_amp and amp_dtype == torch.float16)
    accum_steps = getattr(cfg, 'accum_steps', 1)
    clip_params = [param for group in optimizer.param_groups for param in group['params']]
    enable_param_nan_check = getattr(cfg, 'enable_nan_param_check', False)
    named_params = list(model.named_parameters()) if enable_param_nan_check else ()
    
    losses = []
    v_losses = []
    theta_losses = []
    recon_losses = []
    capacity_losses = []
    mae_V_list = []
    mae_theta_deg_list = []
    mae_P_list = []
    mae_Q_list = []
    
    # åœ¨epochå¼€å§‹æ—¶æ¸…ç©ºæ¢¯åº¦
    optimizer.zero_grad(set_to_none=True)
    
    # åªåœ¨rank0æ˜¾ç¤ºè¿›åº¦æ¡
    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch}', disable=(rank != 0))
    
    for batch_idx, batch in enumerate(progress_bar):
        # === æ•°æ®è¾“å…¥æ£€æµ‹ ===
        try:
            # æ£€æµ‹è¾“å…¥æ•°æ®
            input_issues = []
            if torch.isnan(batch.x).any():
                input_issues.append("x:NaN")
            if torch.isinf(batch.x).any():
                input_issues.append("x:Inf")
            if torch.isnan(batch.edge_attr).any():
                input_issues.append("edge_attr:NaN")
            if torch.isinf(batch.edge_attr).any():
                input_issues.append("edge_attr:Inf")
            
            if input_issues and rank == 0:
                logger.error(f"è¾“å…¥æ•°æ®å¼‚å¸¸ batch {batch_idx}: {', '.join(input_issues)}")
                logger.error(f"  - batch size: {batch.num_graphs if hasattr(batch, 'num_graphs') else 'unknown'}")
                logger.error(f"  - num_nodes: {batch.x.shape[0]}, num_edges: {batch.edge_attr.shape[0]}")
                continue  # è·³è¿‡å¼‚å¸¸æ•°æ®
        except Exception as e:
            if rank == 0:
                logger.error(f"æ•°æ®æ£€æµ‹å‡ºé”™ batch {batch_idx}: {e}")
            continue
        
        batch = batch.to(cfg.device, non_blocking=True)
        
        # DDP no_syncä¼˜åŒ–ï¼šå‡å°‘æ¢¯åº¦åŒæ­¥æ¬¡æ•°
        is_accumulating = (batch_idx + 1) % accum_steps != 0
        sync_ctx = (model.no_sync() if (hasattr(model, "no_sync") and 
                    is_accumulating and accum_steps > 1) else nullcontext())
        
        with sync_ctx:
            # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
            with torch.amp.autocast('cuda', enabled=use_amp, dtype=amp_dtype):
                # === æ¨¡å‹å‰å‘ä¼ æ’­ ===
                try:
                    pred = model(batch)
                except Exception as e:
                    # é’ˆå¯¹ CUDA ç¨€ç–ç®—å­ä¸æ”¯æŒ bf16 çš„é€€é¿æ–¹æ¡ˆï¼šé™çº§åˆ° fp16 å†è¯•ä¸€æ¬¡
                    msg = str(e)
                    tried_fp16 = False
                    if use_amp and amp_dtype == torch.bfloat16 and "addmm_sparse_cuda" in msg:
                        try:
                            tried_fp16 = True
                            with torch.amp.autocast('cuda', enabled=True, dtype=torch.float16):
                                pred = model(batch)
                        except Exception as e2:
                            if rank == 0:
                                logger.error(f"æ¨¡å‹å‰å‘ä¼ æ’­å¤±è´¥ batch {batch_idx} (fp16 fallback): {e2}")
                            # ä¿å­˜å‡ºé”™çš„batchåˆ°logsç›®å½•
                            if rank == 0:
                                debug_path = os.path.join(cfg.log_dir, f'debug_batch_{batch_idx}_epoch_{epoch}.pt')
                                torch.save(batch, debug_path)
                                logger.error(f"é—®é¢˜batchå·²ä¿å­˜è‡³: {debug_path}")
                            continue
                    else:
                        if rank == 0:
                            logger.error(f"æ¨¡å‹å‰å‘ä¼ æ’­å¤±è´¥ batch {batch_idx}: {e}")
                            # ä¿å­˜å‡ºé”™çš„batchåˆ°logsç›®å½•
                            debug_path = os.path.join(cfg.log_dir, f'debug_batch_{batch_idx}_epoch_{epoch}.pt')
                            torch.save(batch, debug_path)
                            logger.error(f"é—®é¢˜batchå·²ä¿å­˜è‡³: {debug_path}")
                        continue
                
                if 'V_pred' not in pred or 'sincos_pred' not in pred:
                    raise RuntimeError("V-Î¸è·¯çº¿ç¼ºå°‘å¿…è¦å­—æ®µï¼šV_pred æˆ– sincos_pred")
                if not hasattr(batch, 'y_bus_V') or not hasattr(batch, 'y_edge_sincos'):
                    raise RuntimeError("V-Î¸è·¯çº¿ç¼ºå°‘æ ‡ç­¾ï¼šy_bus_V æˆ– y_edge_sincos")

                loss, loss_dict = compute_loss_vtheta(pred, batch, cfg, rank)
                # æ¢¯åº¦ç´¯ç§¯ï¼šæŸå¤±é™¤ä»¥ç´¯ç§¯æ­¥æ•°
                loss = loss / accum_steps
                
                # === é¢„æµ‹å€¼NaNæ£€æµ‹ ===
                pred_issues = []
                for key, tensor in pred.items():
                    if isinstance(tensor, torch.Tensor):
                        if torch.isnan(tensor).any():
                            pred_issues.append(f"{key}:NaN")
                        elif torch.isinf(tensor).any():
                            pred_issues.append(f"{key}:Inf")
                
                if pred_issues:
                    if rank == 0:  # åªåœ¨ä¸»è¿›ç¨‹è®°å½•é”™è¯¯
                        logger.error(f"é¢„æµ‹å€¼å¼‚å¸¸: {', '.join(pred_issues)} åœ¨batch {batch_idx}, epoch {epoch}")
                    # ä¿å­˜NaNé¢„æµ‹çš„batch
                    if rank == 0:
                        debug_path = os.path.join(cfg.log_dir, f'nan_pred_batch_{batch_idx}_epoch_{epoch}.pt')
                        torch.save(batch, debug_path)
                        logger.error(f"NaNé¢„æµ‹batchå·²ä¿å­˜è‡³: {debug_path}")
                
                # NaNæ£€æµ‹å’Œä¿æŠ¤
                if torch.isnan(loss) or torch.isinf(loss):
                    if rank == 0:
                        logger.warning(f"æ£€æµ‹åˆ°NaN/InfæŸå¤±åœ¨batch {batch_idx}, epoch {epoch}ï¼Œè·³è¿‡æ­¤batch")
                        logger.warning(f"  æŸå¤±å€¼: {loss.item()}")
                        debug_path = os.path.join(cfg.log_dir, f'nan_loss_batch_{batch_idx}_epoch_{epoch}.pt')
                        torch.save(batch, debug_path)
                        logger.warning(f"NaNæŸå¤±batchå·²ä¿å­˜è‡³: {debug_path}")
                    continue
            
            # åå‘ä¼ æ’­ï¼ˆä½¿ç”¨scalerå¤„ç†æ··åˆç²¾åº¦ï¼‰
            if amp_dtype == torch.float16:
                scaler.scale(loss).backward()
            else:
                loss.backward()
        
        # æ¯accum_stepsæ­¥æˆ–æœ€åä¸€æ‰¹æ—¶æ›´æ–°å‚æ•°
        if (batch_idx + 1) % accum_steps == 0 or (batch_idx + 1) == len(train_loader):
            if amp_dtype == torch.float16:
                # æ¢¯åº¦è£å‰ªï¼ˆç»Ÿä¸€è£å‰ªæ‰€æœ‰å‚æ•°ç»„ï¼‰
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(clip_params, cfg.grad_clip)
                
                # ç§»é™¤äº†physics_alphaç›¸å…³çš„æ¢¯åº¦é™åˆ¶
                
                # å‚æ•°æ›´æ–°
                scaler.step(optimizer)
                scaler.update()
            else:
                # bf16ä¸éœ€è¦scalerï¼›åŒæ ·è£å‰ªæ‰€æœ‰å‚æ•°ç»„
                torch.nn.utils.clip_grad_norm_(clip_params, cfg.grad_clip)
                
                # ç§»é™¤äº†physics_alphaç›¸å…³çš„æ¢¯åº¦é™åˆ¶
                
                optimizer.step()
            
            # é™åˆ¶uncertaintyå‚æ•°èŒƒå›´ï¼Œé˜²æ­¢æƒé‡å¤±æ§
            if hasattr(supervised_loss_fn, 'u'):
                with torch.no_grad():
                    supervised_loss_fn.u.clamp_(-3.0, 3.0)
            
            # ç§»é™¤äº†physics_alphaå‚æ•°çº¦æŸ
            
            # === å‚æ•°NaNæ£€æµ‹ ===
            if enable_param_nan_check:
                nan_params = []
                for name, param in named_params:
                    if torch.isnan(param).any():
                        nan_params.append(name)
                    elif torch.isinf(param).any():
                        nan_params.append(f"{name}(Inf)")

                if nan_params and rank == 0:  # åªåœ¨rank0è®°å½•
                    logger.error(f"å‚æ•°å˜æˆNaN/Inf: {', '.join(nan_params[:5])}{'...' if len(nan_params) > 5 else ''}")
                    logger.error(f"åœ¨ epoch {epoch}, batch {batch_idx} å‚æ•°æ›´æ–°åå‘ç°å¼‚å¸¸")
                    # æ£€æŸ¥æ¢¯åº¦èŒƒæ•°
                    grad_norm = torch.nn.utils.clip_grad_norm_(clip_params, float('inf'))
                    logger.error(f"æ¢¯åº¦èŒƒæ•°: {grad_norm:.6f}")
                    # å¯ä»¥é€‰æ‹©æå‰ç»ˆæ­¢æˆ–è€…é‡ç½®å‚æ•°
                
            optimizer.zero_grad(set_to_none=True)
        
        # è®°å½•
        losses.append(loss_dict['total'])
        v_losses.append(loss_dict['loss_v'])
        theta_losses.append(loss_dict.get('loss_theta', 0.0))
        recon_losses.append(loss_dict.get('loss_recon', 0.0))
        if 'loss_capacity' in loss_dict:
            capacity_losses.append(loss_dict['loss_capacity'])
        if 'mae_V' in loss_dict:
            mae_V_list.append(loss_dict['mae_V'])
        if 'mae_theta_deg' in loss_dict:
            mae_theta_deg_list.append(loss_dict['mae_theta_deg'])
        if 'mae_P' in loss_dict:
            mae_P_list.append(loss_dict['mae_P'])
        if 'mae_Q' in loss_dict:
            mae_Q_list.append(loss_dict['mae_Q'])
        
        # æ›´æ–°è¿›åº¦æ¡ï¼ˆæ ¹æ®è·¯çº¿æ˜¾ç¤ºä¸åŒæŒ‡æ ‡ï¼‰
        postfix_dict = {
            'L_total': f"{loss_dict['total']:.2e}",
            'L_V': f"{loss_dict.get('loss_v', 0.0):.2e}",
            'L_Î¸': f"{loss_dict.get('loss_theta', 0.0):.2e}",
            'L_recon': f"{loss_dict.get('loss_recon', 0.0):.2e}",
            'MAE_V': f"{loss_dict.get('mae_V', 0.0):.4f}",
            'MAE_Î¸Â°': f"{loss_dict.get('mae_theta_deg', 0.0):.2f}",
            'MAE_P': f"{loss_dict.get('mae_P', 0.0):.3f}",
        }
        if 'loss_capacity' in loss_dict:
            postfix_dict['L_cap'] = f"{loss_dict['loss_capacity']:.2e}"
        
        # å®šæœŸæ˜¾ç¤ºKendallç»Ÿè®¡ï¼ˆæ¯100ä¸ªbatchï¼Œä»…é€‚ç”¨äºä¼ ç»Ÿè·¯çº¿ï¼‰
        if batch_idx % 100 == 0 and 'kendall_stats' in loss_dict:
            stats = loss_dict['kendall_stats']
            if 'eff_weight' in stats:
                postfix_dict['w_v'] = f"{stats['eff_weight'][0]:.2f}"
                postfix_dict['w_Î¸'] = f"{stats['eff_weight'][1]:.2f}"
        
        progress_bar.set_postfix(postfix_dict)
        
        # TensorBoardè®°å½•
        global_step = epoch * len(train_loader) + batch_idx
        if batch_idx % cfg.log_interval == 0:
            writer.add_scalar('Train/Loss', loss_dict['total'], global_step)
            writer.add_scalar('Train/Loss_V', loss_dict['loss_v'], global_step)
            writer.add_scalar('Train/Loss_theta', loss_dict.get('loss_theta', 0.0), global_step)
            writer.add_scalar('Train/Loss_recon', loss_dict.get('loss_recon', 0.0), global_step)
            if 'loss_capacity' in loss_dict:
                writer.add_scalar('Train/Loss_capacity', loss_dict['loss_capacity'], global_step)
            if 'mae_V' in loss_dict:
                writer.add_scalar('Train/MAE_V', loss_dict['mae_V'], global_step)
            if 'mae_theta_deg' in loss_dict:
                writer.add_scalar('Train/MAE_theta_deg', loss_dict['mae_theta_deg'], global_step)
            if 'mae_P' in loss_dict:
                writer.add_scalar('Train/MAE_P', loss_dict['mae_P'], global_step)
            if 'mae_Q' in loss_dict:
                writer.add_scalar('Train/MAE_Q', loss_dict['mae_Q'], global_step)
    
    avg_loss = np.mean(losses)
    avg_v_loss = np.mean(v_losses) if v_losses else 0.0
    avg_theta_loss = np.mean(theta_losses) if theta_losses else 0.0
    avg_recon_loss = np.mean(recon_losses) if recon_losses else 0.0
    avg_capacity_loss = np.mean(capacity_losses) if capacity_losses else 0.0
    avg_mae_P = float(np.mean(mae_P_list)) if mae_P_list else 0.0
    avg_mae_Q = float(np.mean(mae_Q_list)) if mae_Q_list else 0.0
    avg_mae_V = float(np.mean(mae_V_list)) if mae_V_list else 0.0
    avg_mae_theta = float(np.mean(mae_theta_deg_list)) if mae_theta_deg_list else 0.0
    logger.info(
        f"Epoch {epoch} - Train Loss: {avg_loss:.2e} "
        f"(L_V: {avg_v_loss:.2e}, L_theta: {avg_theta_loss:.2e}, L_recon: {avg_recon_loss:.2e}, "
        f"L_cap: {avg_capacity_loss:.2e}, MAE_V: {avg_mae_V:.4f}, MAE_Î¸Â°: {avg_mae_theta:.2f}, "
        f"MAE_P: {avg_mae_P:.3f}, MAE_Q: {avg_mae_Q:.3f})"
    )
    
    return avg_loss


def validate_simple(model, val_loader, supervised_loss_fn, epoch, writer, logger, rank=0):
    """éªŒè¯æ¨¡å‹ï¼ˆV-Î¸ è·¯çº¿ï¼‰"""
    model.eval()

    losses = []
    v_losses = []
    theta_losses = []
    recon_losses = []
    capacity_losses = []
    mae_V_list = []
    mae_theta_deg_list = []
    mae_P_list = []
    mae_Q_list = []

    with torch.no_grad():
        for batch in tqdm(val_loader, desc='Validation', disable=(rank != 0)):
            batch = batch.to(cfg.device, non_blocking=True)

            pred = model(batch)
            if 'V_pred' not in pred or 'sincos_pred' not in pred:
                continue
            if not hasattr(batch, 'y_bus_V') or not hasattr(batch, 'y_edge_sincos'):
                continue

            loss, loss_dict = compute_loss_vtheta(pred, batch, cfg, rank)

            losses.append(loss_dict['total'])
            v_losses.append(loss_dict['loss_v'])
            theta_losses.append(loss_dict.get('loss_theta', 0.0))
            recon_losses.append(loss_dict.get('loss_recon', 0.0))
            if 'loss_capacity' in loss_dict:
                capacity_losses.append(loss_dict['loss_capacity'])
            if 'mae_V' in loss_dict:
                mae_V_list.append(loss_dict['mae_V'])
            if 'mae_theta_deg' in loss_dict:
                mae_theta_deg_list.append(loss_dict['mae_theta_deg'])
            if 'mae_P' in loss_dict:
                mae_P_list.append(loss_dict['mae_P'])
            if 'mae_Q' in loss_dict:
                mae_Q_list.append(loss_dict['mae_Q'])

    avg_loss = np.mean(losses) if losses else 0.0
    avg_v_loss = np.mean(v_losses) if v_losses else 0.0
    avg_theta_loss = np.mean(theta_losses) if theta_losses else 0.0
    avg_recon_loss = np.mean(recon_losses) if recon_losses else 0.0
    avg_capacity_loss = np.mean(capacity_losses) if capacity_losses else 0.0

    val_select = avg_v_loss + avg_theta_loss + avg_recon_loss + avg_capacity_loss

    writer.add_scalar('Val/Loss', avg_loss, epoch)
    writer.add_scalar('Val/Loss_V', avg_v_loss, epoch)
    writer.add_scalar('Val/Loss_theta', avg_theta_loss, epoch)
    writer.add_scalar('Val/Loss_recon', avg_recon_loss, epoch)
    writer.add_scalar('Val/Loss_capacity', avg_capacity_loss, epoch)
    writer.add_scalar('Val/SelectMetric', val_select, epoch)
    if mae_V_list:
        writer.add_scalar('Val/MAE_V', float(np.mean(mae_V_list)), epoch)
    if mae_theta_deg_list:
        writer.add_scalar('Val/MAE_theta_deg', float(np.mean(mae_theta_deg_list)), epoch)
    if mae_P_list:
        writer.add_scalar('Val/MAE_P', float(np.mean(mae_P_list)), epoch)
    if mae_Q_list:
        writer.add_scalar('Val/MAE_Q', float(np.mean(mae_Q_list)), epoch)

    logger.info(
        f"Epoch {epoch} - Val Loss: {avg_loss:.2e} | SelectMetric: {val_select:.2e} "
        f"(L_V: {avg_v_loss:.2e}, L_theta: {avg_theta_loss:.2e}, L_recon: {avg_recon_loss:.2e}, "
        f"L_cap: {avg_capacity_loss:.2e})"
    )

    return {'total': avg_loss, 'select': val_select}


def train_simple(model, train_loader, val_loader, writer, logger, rank=0, start_epoch=1, resume_path=None):
    """å®Œæ•´è®­ç»ƒæµç¨‹ï¼ˆæ”¯æŒDDPï¼‰"""
    # è·å–åº•å±‚æ¨¡å‹ï¼ˆå¤„ç†DDPåŒ…è£…ï¼‰
    unwrapped_model = model.module if hasattr(model, 'module') else model

    # ä»… PQ è·¯çº¿ï¼Œä¸ä½¿ç”¨ä¸ç¡®å®šæ€§æŸå¤±
    supervised_loss_fn = None
    
    # ä¼˜åŒ–å™¨ï¼šä¸¤ç»„å‚æ•°ï¼ˆæ¨¡å‹ + Kendallï¼‰
    # ä¼˜åŒ–å™¨å‚æ•°ç»„ï¼šPQ è·¯çº¿ä¸åŠ å…¥ Kendall å‚æ•°
    optimizer = torch.optim.Adam([
        {'params': model.parameters(), 'lr': cfg.lr, 'weight_decay': cfg.weight_decay},
    ])
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    if cfg.lr_scheduler == 'cosine':
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=cfg.epochs
        )
    elif cfg.lr_scheduler == 'step':
        scheduler = torch.optim.lr_scheduler.MultiStepLR(
            optimizer, milestones=cfg.lr_decay_epochs, gamma=cfg.lr_decay_rate
        )
    elif cfg.lr_scheduler == 'warm':
        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
            optimizer, T_0=cfg.warm_period, T_mult=1, eta_min=1e-6
        )
    elif cfg.lr_scheduler == 'cosine_restart':
        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
            optimizer, T_0=15, T_mult=1, eta_min=cfg.lr * 0.05
        )
    elif cfg.lr_scheduler == 'warmup_cosine':
        def lr_lambda(epoch):
            if epoch < cfg.warmup_epochs:
                # é¢„çƒ­é˜¶æ®µï¼šä»0çº¿æ€§ä¸Šå‡åˆ°1
                return epoch / cfg.warmup_epochs
            elif epoch < cfg.cosine_start_epoch:
                # ç¨³å®šé˜¶æ®µï¼šä¿æŒåˆå§‹å­¦ä¹ ç‡
                return 1.0
            else:
                # ä½™å¼¦é€€ç«é˜¶æ®µ
                progress = (epoch - cfg.cosine_start_epoch) / (cfg.epochs - cfg.cosine_start_epoch)
                return 0.5 * (1 + np.cos(np.pi * progress))
        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
    else:
        scheduler = None
    
    # è®­ç»ƒå¾ªç¯
    best_val_loss = float('inf')
    patience_counter = 0
    
    for epoch in range(start_epoch, cfg.epochs + 1):
        # æ›´æ–°DistributedSamplerçš„epochï¼ˆé‡è¦ï¼ï¼‰
        if hasattr(train_loader, 'sampler') and isinstance(train_loader.sampler, DistributedSampler):
            train_loader.sampler.set_epoch(epoch)
        elif hasattr(train_loader, 'loader') and hasattr(train_loader.loader, 'sampler') and isinstance(train_loader.loader.sampler, DistributedSampler):
            train_loader.loader.sampler.set_epoch(epoch)
        
        if rank == 0:
            logger.info(f"\n{'='*50}")
            logger.info(f"Epoch {epoch}/{cfg.epochs}")
        
        # è®­ç»ƒ
        train_loss = train_epoch_simple(model, train_loader, optimizer, supervised_loss_fn, epoch, writer, logger, rank)
        
        # éªŒè¯
        if epoch % cfg.val_interval == 0:
            val_stats = validate_simple(model, val_loader, supervised_loss_fn, epoch, writer, logger, rank)
            val_total = val_stats['total']
            val_select = val_stats['select']
            
            # ç›´æ¥ä½¿ç”¨SelectMetricä½œä¸ºè¯„ä¼°æŒ‡æ ‡ï¼ˆå·²ç»æ˜¯åˆç†çš„ç»„åˆï¼‰
            current_metric = val_select
                
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if current_metric < best_val_loss:
                best_val_loss = current_metric
                patience_counter = 0
                
                # å¤„ç†DataParallelåŒ…è£…
                model_state = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()
                
                checkpoint = {
                    'epoch': epoch,
                    'model_state_dict': model_state,
                    'optimizer_state_dict': optimizer.state_dict(),
                    'val_loss': val_total,
                    'val_select': val_select,
                    'config': cfg
                }
                
                # åªåœ¨rank0ä¿å­˜æ¨¡å‹
                if rank == 0:
                    if supervised_loss_fn is not None:
                        checkpoint['uncertainty_state_dict'] = supervised_loss_fn.state_dict()
                    best_path = os.path.join(cfg.checkpoint_dir, 'best_model.pt')
                    torch.save(checkpoint, best_path)
                    logger.info(f"âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹ (SelectMetric: {current_metric:.2e})")
            else:
                patience_counter += 1
                
                if patience_counter >= cfg.patience:
                    logger.info(f"æ—©åœ: éªŒè¯æŸå¤±æœªæ”¹å–„ {cfg.patience} epochs")
                    break
        
        # å®šæœŸä¿å­˜ï¼ˆåªåœ¨rank0ï¼‰
        if epoch % cfg.save_interval == 0 and rank == 0:
            checkpoint_path = os.path.join(
                cfg.checkpoint_dir, f'checkpoint_epoch_{epoch}.pt'
            )
            model_state = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()
            save_obj = {
                'epoch': epoch,
                'model_state_dict': model_state,
                'optimizer_state_dict': optimizer.state_dict(),
                'config': cfg
            }
            if supervised_loss_fn is not None:
                save_obj['uncertainty_state_dict'] = supervised_loss_fn.state_dict()
            torch.save(save_obj, checkpoint_path)
        
        # æ— ä¸ç¡®å®šæ€§æƒé‡å†»ç»“é€»è¾‘ï¼ˆå·²ç§»é™¤ï¼‰
        
        # å­¦ä¹ ç‡è°ƒæ•´
        if scheduler:
            old_lr = optimizer.param_groups[0]['lr']
            scheduler.step()
            new_lr = optimizer.param_groups[0]['lr']
            writer.add_scalar('Train/LR', new_lr, epoch)
            # è®°å½•å­¦ä¹ ç‡å˜åŒ–
            if new_lr > old_lr * 2:  # å­¦ä¹ ç‡çªç„¶å¢å¤§ï¼Œè¯´æ˜restartäº†
                if rank == 0:
                    logger.info(f"ğŸ”¥ å­¦ä¹ ç‡é‡å¯! {old_lr:.2e} â†’ {new_lr:.2e}")
            elif abs(new_lr - old_lr) > 1e-8:
                if rank == 0:
                    logger.info(f"å­¦ä¹ ç‡è°ƒæ•´: {old_lr:.2e} â†’ {new_lr:.2e}")
    
    logger.info(f"\nè®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.2e}")
    return best_val_loss


def evaluate_final(model, test_loader, writer, logger):
    """æœ€ç»ˆæµ‹è¯•é›†è¯„ä¼°ï¼ˆV-Î¸ è·¯çº¿ï¼‰"""
    logger.info("\n" + "=" * 50)
    logger.info("å¼€å§‹æµ‹è¯•é›†è¯„ä¼° (V-Î¸)")
    logger.info("=" * 50)

    mae_V_list = []
    mae_theta_deg_list = []
    mae_P_list = []
    mae_Q_list = []

    with torch.no_grad():
        for batch in test_loader:
            batch = batch.to(cfg.device, non_blocking=True)
            pred = model(batch)
            if 'V_pred' not in pred or 'sincos_pred' not in pred:
                continue
            if not hasattr(batch, 'y_bus_V') or not hasattr(batch, 'y_edge_sincos'):
                continue

            V_pred = pred['V_pred']
            sincos_pred = pred['sincos_pred']
            edge_pq_pred = pred.get('edge_pq')

            y_V = batch.y_bus_V.to(cfg.device)
            y_sincos = batch.y_edge_sincos.to(cfg.device)
            y_edge_pq = batch.y_edge_pq.to(cfg.device) if hasattr(batch, 'y_edge_pq') else None

            mae_V_list.append(torch.abs(V_pred - y_V).mean().item())

            cos_err = (sincos_pred * y_sincos).sum(dim=1).clamp(-1, 1)
            mae_theta_deg_list.append(torch.rad2deg(torch.acos(cos_err).mean()).item())

            if edge_pq_pred is not None and y_edge_pq is not None:
                mae_P_list.append(torch.abs(edge_pq_pred[:, :2] - y_edge_pq[:, :2]).mean().item())
                mae_Q_list.append(torch.abs(edge_pq_pred[:, 2:] - y_edge_pq[:, 2:]).mean().item())

    def _avg(values):
        return float(sum(values) / len(values)) if values else float('nan')

    metrics = {
        'mae_V': _avg(mae_V_list),
        'mae_theta_deg': _avg(mae_theta_deg_list),
        'mae_P': _avg(mae_P_list),
        'mae_Q': _avg(mae_Q_list),
    }

    logger.info(
        f"  ç”µå‹MAE: {metrics['mae_V']:.6f} p.u., "
        f"ç›¸è§’MAE: {metrics['mae_theta_deg']:.4f}Â°, "
        f"Pé‡æ„MAE: {metrics['mae_P']:.6f} p.u., "
        f"Qé‡æ„MAE: {metrics['mae_Q']:.6f} p.u."
    )

    writer.add_scalar('Test/MAE_V', metrics['mae_V'])
    writer.add_scalar('Test/MAE_theta_deg', metrics['mae_theta_deg'])
    writer.add_scalar('Test/MAE_P', metrics['mae_P'])
    writer.add_scalar('Test/MAE_Q', metrics['mae_Q'])


def main(resume_path=None):
    """ä¸»å‡½æ•°ï¼ˆæ”¯æŒDDPï¼‰"""
    # ===== DDP åˆå§‹åŒ– =====
    is_ddp, rank, local_rank, world_size, device = setup_ddp()
    cfg.device = device
    
    # åªåœ¨rank0å¤„ç†æ—¥å¿—å’Œé…ç½®
    if rank == 0:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(cfg.log_dir, exist_ok=True)
        os.makedirs(cfg.checkpoint_dir, exist_ok=True)
        os.makedirs(cfg.tensorboard_dir, exist_ok=True)
        
    # æ‰“å°é…ç½®ä¸æ—¥å¿—ï¼ˆä»…rank0ï¼‰
    if rank == 0:
        cfg.print_config()
        # ä¿å­˜é…ç½®
        cfg.save()
        # è®¾ç½®æ—¥å¿—
        logger = setup_logging()
        logger.info(f"å¯åŠ¨BC-GNNè®­ç»ƒæµæ°´çº¿ (DDP: {is_ddp}, World Size: {world_size})")
        # TensorBoard
        writer = SummaryWriter(cfg.tensorboard_dir)
    else:
        # å…¶ä»–rankä½¿ç”¨è™šæ‹Ÿloggerå’Œwriter
        class _Dummy:
            def add_scalar(self, *args, **kwargs): pass
            def add_scalars(self, *args, **kwargs): pass
            def info(self, *args, **kwargs): pass
            def warning(self, *args, **kwargs): pass
            def close(self): pass
        logger = _Dummy()
        writer = _Dummy()
    
    # è®¾ç½®éšæœºç§å­ï¼ˆæ¯ä¸ªrankä¸åŒçš„ç§å­ï¼‰
    set_seed(cfg.seed + rank)
    
    # æ€§èƒ½ä¼˜åŒ–è®¾ç½®
    torch.set_float32_matmul_precision('high')
    if torch.cuda.is_available():
        torch.backends.cudnn.benchmark = True
    
    # åŠ è½½æ•°æ®ï¼ˆéœ€è¦ V1.1 å­—æ®µï¼‰
    logger.info("\nåŠ è½½æ•°æ®...")
    # æ•°æ®åº”è¯¥å·²ç»é€šè¿‡ prepare_dataset.py åˆ’åˆ†å¥½
    train_data, val_data, test_data, voltage_stats = load_data(cfg.data_dir)
    
    # æ•°æ®æ³„æ¼æ£€æŸ¥ä¸å¼ºåˆ¶å»é‡ï¼ˆå…¨å±€ä¸€è‡´ï¼Œå…ˆæ£€æŸ¥åä¿®å¤ï¼›ä»¥ test > val > train çš„ä¼˜å…ˆçº§ä¿ç•™æ ·æœ¬ï¼‰
    def _make_id_list(dataset):
        """ç”Ÿæˆä¸æ•°æ®åˆ—è¡¨ä¸€ä¸€å¯¹åº”çš„ç¨³å®š ID åˆ—è¡¨ã€‚"""
        import hashlib
        def _hash_parts(parts: list[bytes]) -> str:
            h = hashlib.sha1()
            for p in parts:
                h.update(p)
            return h.hexdigest()
        ids = []
        for data in dataset:
            if hasattr(data, 'sample_id') and data.sample_id is not None:
                ids.append(str(data.sample_id))
                continue
            if hasattr(data, 'idx') and data.idx is not None:
                ids.append(str(data.idx))
                continue
            k_val = int(getattr(data, 'k', 0))
            n_nodes = int(data.x.size(0)) if hasattr(data, 'x') else -1
            n_edges = int(data.edge_index.size(1)) if hasattr(data, 'edge_index') else -1
            parts = [f"k={k_val},n={n_nodes},e={n_edges}".encode('utf-8')]
            if hasattr(data, 'tie_buses') and data.tie_buses is not None and data.tie_buses.numel() > 0:
                parts.append(data.tie_buses.detach().cpu().numpy().tobytes())
            if hasattr(data, 'tie_corridors') and data.tie_corridors is not None and data.tie_corridors.numel() > 0:
                parts.append(data.tie_corridors.detach().cpu().numpy().tobytes())
            # åŠ å…¥è´Ÿè·ç­¾åï¼ˆåœºæ™¯çº§ï¼‰ï¼šx çš„å‰ä¸¤åˆ— [P_load, Q_load]
            if hasattr(data, 'x') and data.x is not None and data.x.numel() > 0:
                cols = min(2, data.x.size(1))
                parts.append(data.x[:, :cols].detach().cpu().contiguous().numpy().tobytes())
            ids.append(_hash_parts(parts))
        return ids

    # ä»… rank0 æ‰“å°ä¸ä¿®å¤ï¼Œå…¶ä»– rank åŒæ­¥åä½¿ç”¨ä¿®å¤åçš„åˆ—è¡¨
    if rank == 0:
        def get_sample_ids(dataset):
            """ä»æ•°æ®é›†ä¸­æå–ç¨³å¥çš„æ ·æœ¬IDï¼ˆé¿å…ä¼ªé‡å¤è¯¯æŠ¥ï¼‰ã€‚

            ä¼˜å…ˆä½¿ç”¨ Data.sample_idï¼›å¦åˆ™åŸºäºå…³é”®å­—æ®µå†…å®¹è®¡ç®— SHA1ï¼š
            - k å€¼ã€èŠ‚ç‚¹æ•°ã€è¾¹æ•°
            - tie_busesï¼ˆLongTensorï¼‰
            - tie_corridorsï¼ˆLongTensor [C,2]ï¼‰

            è¿™æ ·èƒ½é¿å…ä½¿ç”¨â€œé¦–ä¸ªè´Ÿè·/èŠ‚ç‚¹æ•°â€ç­‰å¼±ç‰¹å¾å¯¼è‡´çš„ç¢°æ’ã€‚
            """
            import hashlib
            import numpy as np

            def _hash_parts(parts: list[bytes]) -> str:
                h = hashlib.sha1()
                for p in parts:
                    h.update(p)
                return h.hexdigest()

            sample_ids = set()
            for data in dataset:
                # 1) æ˜ç¡®çš„ sample_id/idx
                if hasattr(data, 'sample_id') and data.sample_id is not None:
                    sample_ids.add(str(data.sample_id))
                    continue
                if hasattr(data, 'idx') and data.idx is not None:
                    sample_ids.add(str(data.idx))
                    continue

                # 2) ç¨³å¥å“ˆå¸Œï¼ˆåŸºäºå…ƒæ•°æ®+å…³é”®å¼ é‡ï¼‰
                k_val = int(getattr(data, 'k', 0))
                n_nodes = int(data.x.size(0)) if hasattr(data, 'x') else -1
                n_edges = int(data.edge_index.size(1)) if hasattr(data, 'edge_index') else -1
                parts = [
                    f"k={k_val},n={n_nodes},e={n_edges}".encode('utf-8')
                ]
                if hasattr(data, 'tie_buses') and data.tie_buses is not None and data.tie_buses.numel() > 0:
                    parts.append(data.tie_buses.detach().cpu().numpy().tobytes())
                if hasattr(data, 'tie_corridors') and data.tie_corridors is not None and data.tie_corridors.numel() > 0:
                    parts.append(data.tie_corridors.detach().cpu().numpy().tobytes())
                sample_ids.add(_hash_parts(parts))
            return sample_ids
        
        logger.info("æ£€æŸ¥æ•°æ®é›†åˆ’åˆ†...")
        train_ids_list = _make_id_list(train_data)
        val_ids_list = _make_id_list(val_data)
        test_ids_list = _make_id_list(test_data)
        train_ids = set(train_ids_list)
        val_ids = set(val_ids_list)
        test_ids = set(test_ids_list)
        
        # æ£€æŸ¥é‡å 
        train_val_overlap = train_ids & val_ids
        train_test_overlap = train_ids & test_ids
        val_test_overlap = val_ids & test_ids
        
        # è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        logger.info(f"  è®­ç»ƒé›†å”¯ä¸€æ ·æœ¬æ•°: {len(train_ids)}")
        logger.info(f"  éªŒè¯é›†å”¯ä¸€æ ·æœ¬æ•°: {len(val_ids)}")
        logger.info(f"  æµ‹è¯•é›†å”¯ä¸€æ ·æœ¬æ•°: {len(test_ids)}")
        
        if train_val_overlap:
            logger.warning(f"âš ï¸ æ•°æ®æ³„æ¼ï¼train/valé‡å {len(train_val_overlap)}ä¸ªæ ·æœ¬")
        else:
            logger.info("âœ“ train/valæ— é‡å ")
        
        if train_test_overlap:
            logger.warning(f"âš ï¸ æ•°æ®æ³„æ¼ï¼train/testé‡å {len(train_test_overlap)}ä¸ªæ ·æœ¬")
        else:
            logger.info("âœ“ train/testæ— é‡å ")
            
        if val_test_overlap:
            logger.warning(f"âš ï¸ æ•°æ®æ³„æ¼ï¼val/testé‡å {len(val_test_overlap)}ä¸ªæ ·æœ¬")
        else:
            logger.info("âœ“ val/testæ— é‡å ")

        # å¼ºåˆ¶æ‰“æ•£é‡å ï¼šä¼˜å…ˆä¿ç•™ testï¼Œå…¶æ¬¡ valï¼Œæœ€å train
        keep_test = set(test_ids_list)
        keep_val = set(x for x in val_ids_list if x not in keep_test)
        keep_train = set(x for x in train_ids_list if x not in keep_test and x not in keep_val)

        removed_train = len(train_ids_list) - sum(1 for x in train_ids_list if x in keep_train)
        removed_val = len(val_ids_list) - sum(1 for x in val_ids_list if x in keep_val)
        removed_test = len(test_ids_list) - sum(1 for x in test_ids_list if x in keep_test)

        if removed_train or removed_val or removed_test:
            logger.info("æ‰§è¡Œå»é‡/äº’æ–¥ä¿®å¤: ä¼˜å…ˆçº§ test > val > train")
            if removed_train:
                logger.info(f"  - ä» train ç§»é™¤ {removed_train} ä¸ªé‡å æ ·æœ¬")
            if removed_val:
                logger.info(f"  - ä» val ç§»é™¤ {removed_val} ä¸ªé‡å æ ·æœ¬")
            if removed_test:
                logger.info(f"  - ä» test ç§»é™¤ {removed_test} ä¸ªé‡å æ ·æœ¬")

            # æŒ‰ä¿ç•™é›†åˆè¿‡æ»¤æ•°æ®åˆ—è¡¨
            train_data = [d for d, sid in zip(train_data, train_ids_list) if sid in keep_train]
            val_data = [d for d, sid in zip(val_data, val_ids_list) if sid in keep_val]
            test_data = [d for d, sid in zip(test_data, test_ids_list) if sid in keep_test]
            logger.info(f"ä¿®å¤å: train={len(train_data)}, val={len(val_data)}, test={len(test_data)}")
    
    # æ— è®ºæ˜¯å¦ä¸º rank0ï¼Œç¡®ä¿ä¸‰ä»½æ•°æ®äº’æ–¥ï¼ˆä¸ä¸Šé¢ç›¸åŒä¼˜å…ˆçº§è§„åˆ™ï¼‰ï¼Œä¿è¯ä¸€è‡´æ€§
    train_ids_list_all = _make_id_list(train_data)
    val_ids_list_all = _make_id_list(val_data)
    test_ids_list_all = _make_id_list(test_data)
    keep_test_all = set(test_ids_list_all)
    keep_val_all = set(x for x in val_ids_list_all if x not in keep_test_all)
    keep_train_all = set(x for x in train_ids_list_all if x not in keep_test_all and x not in keep_val_all)
    train_data = [d for d, sid in zip(train_data, train_ids_list_all) if sid in keep_train_all]
    val_data = [d for d, sid in zip(val_data, val_ids_list_all) if sid in keep_val_all]
    test_data = [d for d, sid in zip(test_data, test_ids_list_all) if sid in keep_test_all]

    # åˆ›å»ºDistributedSamplerï¼ˆDDPæ¨¡å¼ï¼‰
    train_sampler = DistributedSampler(train_data, shuffle=True, drop_last=True) if is_ddp else None
    val_sampler = DistributedSampler(val_data, shuffle=False, drop_last=False) if is_ddp else None
    test_sampler = DistributedSampler(test_data, shuffle=False, drop_last=False) if is_ddp else None
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆæ”¯æŒå¤§batchï¼‰
    actual_batch_size = getattr(cfg, 'batch_size', 1)
    train_loader = create_dataloader(
        train_data, batch_size=actual_batch_size, 
        shuffle=(not is_ddp),  # DDPæ—¶ç”±sampleræ§åˆ¶
        sampler=train_sampler,
        num_workers=cfg.num_workers, 
        pin_memory=cfg.pin_memory,
        persistent_workers=True if cfg.persistent_workers and cfg.num_workers > 0 else False,
        prefetch_factor=getattr(cfg, 'prefetch_factor', None)
    )
    val_loader = create_dataloader(
        val_data, batch_size=actual_batch_size, 
        shuffle=False,
        sampler=val_sampler,
        num_workers=cfg.num_workers, 
        pin_memory=cfg.pin_memory,
        persistent_workers=True if cfg.persistent_workers and cfg.num_workers > 0 else False,
        prefetch_factor=getattr(cfg, 'prefetch_factor', None)
    )
    test_loader = create_dataloader(
        test_data, batch_size=actual_batch_size, 
        shuffle=False,
        sampler=test_sampler,
        num_workers=cfg.num_workers, 
        pin_memory=cfg.pin_memory,
        persistent_workers=True if cfg.persistent_workers and cfg.num_workers > 0 else False,
        prefetch_factor=getattr(cfg, 'prefetch_factor', None)
    )
    
    # åˆ›å»ºæ¨¡å‹
    logger.info("\nåˆå§‹åŒ–æ¨¡å‹...")
    # æ¨æ–­ç‰¹å¾ç»´åº¦ï¼ˆä¸å®é™…æ•°æ®å¯¹é½ï¼‰
    sample0 = train_data[0]
    node_in_dim = int(sample0.x.size(1))
    edge_in_dim = int(sample0.edge_attr.size(1))

    # æ£€æŸ¥ V-Î¸ æ‰€éœ€å­—æ®µ
    required = [
        hasattr(sample0, 'tie_buses') and sample0.tie_buses is not None,
        hasattr(sample0, 'tie_corridors') and sample0.tie_corridors is not None,
        hasattr(sample0, 'tie_edge_corridor') and sample0.tie_edge_corridor is not None,
        hasattr(sample0, 'y_bus_V') and sample0.y_bus_V is not None,
        hasattr(sample0, 'y_edge_sincos') and sample0.y_edge_sincos is not None,
    ]
    if not all(required):
        raise RuntimeError('V-Î¸ è·¯çº¿æ‰€éœ€å­—æ®µç¼ºå¤±ï¼štie_buses/tie_corridors/tie_edge_corridor/y_bus_V/y_edge_sincos')
    model = BCGNN(
        node_features=node_in_dim,
        edge_features=edge_in_dim,
        hidden_dim=cfg.hidden_dim,
        voltage_stats=voltage_stats,
        use_voltage_prior=cfg.use_voltage_prior,
        ring_k=getattr(cfg, 'ring_k', 0),
        ring_decay=(getattr(cfg, 'ring_decay', None) if getattr(cfg, 'ring_decay', None) is not None else None),
        ring_use_decayed=getattr(cfg, 'ring_use_decayed', True),
    ).to(cfg.device)

    # torch.compile åŠ é€Ÿï¼ˆåœ¨DDPå‰ï¼‰
    if getattr(cfg, 'use_compile', False) and hasattr(torch, 'compile'):
        try:
            model = torch.compile(model, mode=getattr(cfg, 'compile_mode', 'reduce-overhead'), dynamic=True, fullgraph=False)
            if rank == 0:
                logger.info("âœ“ å¯ç”¨ torch.compile åŠ é€Ÿ")
        except Exception as e:
            if rank == 0:
                logger.warning(f"torch.compile å¯ç”¨å¤±è´¥ï¼Œç»§ç»­æ— ç¼–è¯‘è·¯å¾„: {e}")
    
    # DDPåŒ…è£…
    if is_ddp:
        model = nn.parallel.DistributedDataParallel(
            model,
            device_ids=[local_rank],
            output_device=local_rank,
            find_unused_parameters=False
        )
        if rank == 0:
            logger.info(f"âœ“ å¯ç”¨DDPï¼ŒWorld Size: {world_size}")
    
    # è®°å½•æ¨¡å‹ç»“æ„
    param_count = sum(p.numel() for p in model.parameters())
    logger.info(f"æ¨¡å‹å‚æ•°é‡: {param_count:,}")
    
    # Resumeé€»è¾‘ï¼ˆDDPåŒæ­¥ï¼‰
    start_epoch = 1
    if resume_path:
        if rank == 0:
            logger.info(f"\nä»checkpointæ¢å¤: {resume_path}")
        
        checkpoint = torch.load(resume_path, map_location=cfg.device, weights_only=False)
        
        # æ¢å¤æ¨¡å‹çŠ¶æ€
        if hasattr(model, 'module'):
            model.module.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint['model_state_dict'])
        
        start_epoch = checkpoint.get('epoch', 1) + 1
        if rank == 0:
            logger.info(f"ä»Epoch {start_epoch}å¼€å§‹è®­ç»ƒ")
    
    # DDPåŒæ­¥
    if is_ddp:
        dist.barrier()
    
    # è®­ç»ƒ
    logger.info("\nå¼€å§‹è®­ç»ƒ...")
    start_time = time.time()
    
    best_val_loss = train_simple(model, train_loader, val_loader, writer, logger, rank, start_epoch, resume_path)
    
    train_time = time.time() - start_time
    logger.info(f"è®­ç»ƒè€—æ—¶: {train_time/60:.1f} åˆ†é’Ÿ")
    
    # DDPåŒæ­¥
    if is_ddp:
        dist.barrier()
    
    # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼ˆåªåœ¨rank0ï¼‰
    if cfg.evaluate_after_training and rank == 0:
        logger.info("\nåŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œè¯„ä¼°...")
        best_checkpoint = torch.load(
            os.path.join(cfg.checkpoint_dir, 'best_model.pt'),
            map_location=device,
            weights_only=False
        )
        # å¤„ç†DDPåŒ…è£…
        if hasattr(model, 'module'):
            model.module.load_state_dict(best_checkpoint['model_state_dict'])
        else:
            model.load_state_dict(best_checkpoint['model_state_dict'])
        model.eval()
        
        # è¯„ä¼°
        evaluate_final(model, test_loader, writer, logger)
    
    # å…³é—­
    writer.close()
    logger.info("\næµæ°´çº¿å®Œæˆï¼")
    logger.info(f"æ—¥å¿—ä¿å­˜åœ¨: {cfg.log_dir}")
    logger.info(f"æ¨¡å‹ä¿å­˜åœ¨: {cfg.checkpoint_dir}")
    logger.info(f"TensorBoard: tensorboard --logdir {cfg.tensorboard_dir}")
    
    # é”€æ¯DDPè¿›ç¨‹ç»„
    if is_ddp and dist.is_initialized():
        dist.destroy_process_group()


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--resume', type=str, default=None, help='Resume from checkpoint path')
    args = parser.parse_args()
    main(args.resume)
